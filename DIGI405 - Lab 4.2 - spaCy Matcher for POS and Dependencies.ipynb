{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dada6117-5127-4c85-8a33-02f3ab30192e",
   "metadata": {},
   "source": [
    "# DIGI405 Lab 4.2: spaCy Matcher for Parts of Speech and Dependency Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc436209-d7dc-4696-b457-bf99cf668e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher, DependencyMatcher\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa83bb-0656-494c-a6e7-086706a1ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"textcat\", \"lemmatizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a90cc-4f2f-468c-9d60-84a0363695cd",
   "metadata": {},
   "source": [
    "### spaCy Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566995d-07a6-4ecc-b911-9da77ab94bfc",
   "metadata": {},
   "source": [
    "We are going to start by using part of speech tags for corpus analysis. For this, we'll use the [spaCy Matcher](https://spacy.io/api/matcher). This can be very useful for finding simple patterns. Below, we'll try to match all numbers with a percentage symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178c856-893b-461a-991d-ec289456fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list1 = [\n",
    "    \"The onshore processing sector makes the largest contribution to employment with about 65% of total employment related to tuna fisheries coming from this sector.\",\n",
    "    \"Dr Norman says a 3% levy on income above $70,00 and a business tax rate of 30% for five-and-a-half years could have already raised nearly one-fifth of the total cost of the rebuild of $5.5 billion\",\n",
    "    \"The proportion of people agreeing that climate change is a serious issue fell to 36%, from almost 43% last year.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd3c5b-fca9-49e5-a05d-b7dbe5897f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = list(nlp.pipe(text_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63a02c-c8c9-4ed8-8166-379be84f12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher1 = Matcher(nlp.vocab)\n",
    "\n",
    "# match a number followed by a %\n",
    "pattern1 = [{\"POS\": \"NUM\"}, {\"ORTH\": \"%\"}]\n",
    "matcher1.add(\"symbol\", [pattern1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e3b8b-de0b-43e3-b185-28a23c5cc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(docs1):\n",
    "    matches = matcher1(doc)\n",
    "\n",
    "    # print the results\n",
    "    print(\"=== Doc {} ===\".format(idx))\n",
    "    print(\"Number of matches: \", len(matches))\n",
    "    if matches:\n",
    "        print(\"Matches:\", set([doc[start:end].text for match_id, start, end in matches]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936aab5-5790-4590-8dfc-2657767d4bf9",
   "metadata": {},
   "source": [
    "### Matching Parts of Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a1af3-81b6-496a-8384-ae313fef3d27",
   "metadata": {},
   "source": [
    "Say we want to find every VERB that is related to a query word in a list of texts. We can try to use the Matcher for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a0999b-af47-4a48-9e0f-26108dddc9ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b165959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through the notebook using the query word 'economists' as shown below before experimenting with your own query\n",
    "query_word = \"economists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab336510-bd5f-4ce7-9609-6ad923da501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example news texts\n",
    "text_list2 = [\n",
    "    \"New Zealand's Sydney correspondent says some economists are now wondering whether reform is possible in the current climate\",\n",
    "    \"The anticipated recession and is growing faster than economists expected, inflation hit 40-year highs in 2022\",\n",
    "    \"Economists are warning of increased risk of a 'hard landing' - the RBNZ tightening of monetary conditions bringing the economy to a screeching halt\",\n",
    "    \"An economist is calling for a new law requiring the next government to keep track of what economists are studying, in case any of it turns out to be useful.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28563224-cab5-4231-9bcc-63872689beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2 = list(nlp.pipe(text_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409147b8-eec9-4e66-8551-04606aef2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matcher using the vocab from spaCy's language model\n",
    "matcher2 = Matcher(nlp.vocab)\n",
    "\n",
    "# match a verb following the word query_word\n",
    "pattern2 = [{\"LOWER\": query_word}, {\"POS\": \"VERB\"}]\n",
    "matcher2.add(\"economist\", [pattern2])\n",
    "\n",
    "pattern3 = [{\"LOWER\": query_word}, {\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}]\n",
    "matcher2.add(\"economist\", [pattern3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46f3a7-835c-4347-9ad9-df58c66c04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(docs2):\n",
    "    matches = matcher2(doc)\n",
    "\n",
    "    # print the results\n",
    "    print(\"=== Doc {} ===\".format(idx))\n",
    "    print(\"Number of matches: \", len(matches))\n",
    "    if matches:\n",
    "        print(\"Matches:\", set([doc[start:end].text for match_id, start, end in matches]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4d913-66c1-45f8-9568-f22465ac9e36",
   "metadata": {},
   "source": [
    "### Dependency matching\n",
    "\n",
    "Our basic matcher above initially found one instance of the query word 'economists' and a related verb. This was because it matched only the string directly following the word 'economists'.\n",
    "\n",
    "You can uncomment the lines for pattern3, and see how this matches 'economist' + auxiliary verb ('are' in this case) + verb.\n",
    "\n",
    "This is nice but, as you can see, it doesn't capture our first example: \"some economists are now wondering whether...\". The problem here is that there are many ways sentences can be put together, and it is possible for the position of the verb to vary a lot. We will have a hard time predicting all these possible variants.\n",
    "\n",
    "Instead, we can use a more powerful approach, building on the grammatical dependencies that spaCy can extract. We will also try to match 'economist' singular and 'economists' plural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8aa4b-ad1a-4a17-b7b8-0357914f9b26",
   "metadata": {},
   "source": [
    "### Visualisation of grammatical dependencies\n",
    "\n",
    "displaCy provides a visualiser for dependencies, allowing you to see the grammatical structure of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e778c-756d-43bb-ab7b-1f749f1be1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display an example - paste in your own text below.\n",
    "text_to_parse = nlp(\n",
    "    \"New Zealand's Sydney correspondent says some economists are now wondering whether reform is possible in the current climate\"\n",
    ")\n",
    "\n",
    "html = displacy.render(text_to_parse, options={\"fine_grained\": True}, jupyter = False)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d7e36-421b-4244-b8d8-9dccd834a61d",
   "metadata": {},
   "source": [
    "spaCy's [dependency matcher documentation](https://spacy.io/usage/rule-based-matching#dependencymatcher) explains how to match on a specific a relation within the dependency structure. \n",
    "\n",
    "In the example above, the word 'economists' is a dependant of the verb 'wondering'. We can see this because displaCy draws the arrow from 'wondering' to 'economists'.\n",
    "\n",
    "To match this pattern, we start by creating a pattern for the word 'economists' (lowercased, so it will also match if the first letter is a capital E). \n",
    "\n",
    "We have also added a regular expression here to capture both single and plural instances of \"economist\". The ```(s)?``` indicates an optional group that will be matched if it is present. In the second part of Pattern 4 we then match any verb which is the immediate 'head' node in relation to the word economists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198a849-ba6f-4b55-aedb-10f218c1cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern4 = [\n",
    "  # anchor token: economists (lowercased)\n",
    "  {\n",
    "    \"RIGHT_ID\": query_word,\n",
    "    \"RIGHT_ATTRS\": {\"LOWER\": {\"REGEX\": \"economist(s)?\"}}\n",
    "  },\n",
    "  # find verbs higher in the dependency chain from query_word\n",
    "  # they could appear before or after the word query_word\n",
    "  {\n",
    "    \"LEFT_ID\": query_word,\n",
    "    \"REL_OP\": \"<\",\n",
    "    \"RIGHT_ID\": \"verb\",\n",
    "    \"RIGHT_ATTRS\": {\"POS\": \"VERB\"}\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a4431-b512-4536-90ad-4cad7e5ebaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dependency matcher and add patterns\n",
    "\n",
    "dep_matcher = DependencyMatcher(nlp.vocab)\n",
    "dep_matcher.add(query_word, [pattern4])\n",
    "\n",
    "# to add further patterns, define them above,\n",
    "# then extend the list, as in the next line:\n",
    "#dep_matcher.add(query_word, [pattern4, pattern5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73d3fb-ae5e-4d17-9e6e-97fb312ed2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(docs2):\n",
    "    matches = dep_matcher(doc)\n",
    "\n",
    "    # print the results\n",
    "    print(\"=== Doc {} ===\".format(idx))\n",
    "    print(\"Number of matches: \", len(matches))\n",
    "\n",
    "    for m_index, match in enumerate(matches):\n",
    "        match_id, token_ids = match\n",
    "        for i in range(len(token_ids)):\n",
    "            print(pattern4[i][\"RIGHT_ID\"] + \":\", doc[token_ids[i]].text)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f3dd4-b9ea-4e83-80dc-242bbd0087fb",
   "metadata": {},
   "source": [
    "### Dependency match operators (REL_OP)\n",
    "\n",
    "To get started all you need are the four simplest operators below. The full list can be found in the [DependencyMatcher documentation](https://spacy.io/usage/rule-based-matching#dependencymatcher).\n",
    "\n",
    "| Symbol | Description |\n",
    "| --- | --- |\n",
    "| A < B | A is the immediate dependent of B. |\n",
    "| A > B | A is the immediate head of B. | \n",
    "| A << B | A is the dependent in a chain to B following dep → head paths. |\n",
    "| A >> B | A is the head in a chain to B following head → dep paths. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748be0f-46c4-43d8-9083-03c8033a7983",
   "metadata": {},
   "source": [
    "### Create a pipeline for multiple texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374738f2-6c26-4134-a98e-b16d16b9abe0",
   "metadata": {},
   "source": [
    "You may have noticed above we use the nlp.pipe command to process a collection of texts. We can pass this a longer list of texts to process.\n",
    "\n",
    "Here we will experiment with the Assignment 1 corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf2ad2-e211-449b-b3c5-bf8e2bd0c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45acb7-abe0-4135-a47a-652007c02ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the csv version of the corpus\n",
    "df = pd.read_csv('cc_all_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667abac2-f070-416e-96b2-9b5f65d27b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889d54f-6415-4dda-876c-4248197d4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts = df['fulltext']\n",
    "\n",
    "# sample a smaller corpus\n",
    "texts = df['fulltext'].sample(frac=0.3, random_state=9)\n",
    "\n",
    "# NB This step will take a while with lots of texts\n",
    "# You can comment/uncomment the lines above to use the full dataset\n",
    "corpus = list(nlp.pipe(texts, batch_size=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17a3ef-3d6c-4a08-91f6-aabe1543e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_counts = Counter()\n",
    "\n",
    "for idx, doc in enumerate(corpus):\n",
    "\n",
    "    matches = dep_matcher(doc)\n",
    "\n",
    "    # iterate over matches starting at the first verb\n",
    "    # and increment in 2s to skip all the matches with query_word\n",
    "\n",
    "    for m_index, match in enumerate(matches):\n",
    "        match_id, token_ids = match\n",
    "\n",
    "        for i in range(len(token_ids))[1::2]:\n",
    "            if matches:\n",
    "                match_id, token_ids = matches[0]\n",
    "                match_counts.update([doc[token_ids[i]].text])\n",
    "                print(pattern4[i][\"RIGHT_ID\"] + \":\", doc[token_ids[i]].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482996a-cf1e-4e39-a225-ade3f6080f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98fbef5-78c2-4c48-a487-c9bd2759c6c3",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde3699-5d9a-49c7-8df8-90d1fb9cd26a",
   "metadata": {},
   "source": [
    "Now try some of the following:\n",
    "\n",
    "* Use the methods introduced in the first two weeks of the course to explore words / phrases of interest in the Assignment 1 corpus. \n",
    "* Select some of these and visualise their dependencies using displaCy.\n",
    "* Adapt / extend either the Matcher or DependencyMatcher to match different patterns of interest. You should consult the spaCy [documentation on linguistic features](https://spacy.io/usage/linguistic-features) for ideas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf6932-b5aa-4047-a8b1-2e2e4a6150c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
